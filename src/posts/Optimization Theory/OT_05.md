---
title: Optimization Theory - Week 5
category: Notes
---

# Constrained Problem

## 2.1 Definition Descent Direction

Let $ f $ be differentiable at $ \mathbf{x} $. If $ \nabla f(\mathbf{x}) \mathbf{d}<0, \mathbf{d} $ is denoted as a descent direction of $ f $ at x.

## 2.2 Lemma 2.2

Let $ X $ be an open set in $ \mathbb{R}^{n} $ and let $ f $ be differentiable at $ \mathbf{x} $. If there is a vector $ \mathbf{d} $ such that $ \nabla f(\mathbf{x}) \mathbf{d}<0 $, then there exists a $ \delta>0 $ such that $ f(\mathbf{x}+\lambda \mathbf{d})<f(\mathbf{x}) $ for all $ \lambda \in(0, \delta) $, so that $ \mathbf{d} $ is a descent direction of $ f $ at $ \mathbf{x} $.

## 2.3 Definition Feasible Direction

Let $ X $ be a set in $ \mathbb{R}^{n} $ and $ \mathbf{x} \in X $. Nonzero vector $ \mathbf{d} $ is denoted as a feasible direction of $ X $ at $ \mathbf{x} $ if there is a $ \delta $ and a differentiable curve $ \boldsymbol{\xi}(t) $ such that
$
\boldsymbol{\xi}(0)=\mathbf{x}, \boldsymbol{\xi}^{\prime}(0)=\mathbf{d}, \boldsymbol{\xi}(t) \in X, t \in(0, \delta)
$

## 2.6 Theorem 2.6

If $ \mathbf{x}^{*} $ is a solution of the problem $ \min \left\{f(\mathbf{x}): \mathbf{x} \in X_{0}, \mathbf{g}(\mathbf{x}) \leq \mathbf{0}\right\} $, then there exists a real number $ \lambda_{0} \geq 0 $, a vector $ \boldsymbol{\lambda} \geq \mathbf{0} $ in $ \mathbb{R}^{m} $, such that
(i) $ \left(\lambda_{0}, \boldsymbol{\lambda}\right) \neq \mathbf{0} $,
(ii) $ \left\langle\boldsymbol{\lambda}, \mathbf{g}\left(\mathbf{x}^{*}\right)\right\rangle=0 $, and
(iii) $ \lambda_{0} \nabla f\left(\mathbf{x}^{*}\right)+\boldsymbol{\lambda}^{t} \nabla \mathbf{g}\left(\mathbf{x}^{*}\right)=\mathbf{0} $.

## 2.7 Theorem Lagrange multiplier

If $ \mathbf{x}^{*} $ is a solution of the problem $ \min \{f(\mathbf{x}): \mathbf{h}(\mathbf{x})=\mathbf{0}\} $ and if the $ k $ gradient vectors $ \nabla h_{j}\left(\mathbf{x}^{*}\right) $ are linearly independent, then there exist unique scalars $ \mu_{j}, j=1, \ldots, k $, such that for each $ i=1, \ldots, n $
$
\frac{\partial f}{\partial x_{i}}\left(\mathbf{x}^{*}\right)+\sum_{j=1}^{k} \mu_{j} \frac{\partial h_{j}\left(\mathbf{x}^{*}\right)}{\partial x_{i}}=0
$
and
$
h_{j}\left(\mathbf{x}^{*}\right)=0, j=1, \ldots, k .
$

## 2.8 Theorem Implicit Function Theorem

If $ \mathbf{x}^{*} $ is a solution of the problem $ \min \{f(\mathbf{x}): \mathbf{h}(\mathbf{x})=\mathbf{0}\} $ and if the $ k $ gradient vectors $ \nabla h_{j}\left(\mathbf{x}^{*}\right) $ are linearly independent, then there exist unique scalars $ \mu_{j}, j=1, \ldots, k $, such that for each $ i=1, \ldots, n $
$
\frac{\partial f}{\partial x_{i}}\left(\mathbf{x}^{*}\right)+\sum_{j=1}^{k} \mu_{j} \frac{\partial h_{j}\left(\mathbf{x}^{*}\right)}{\partial x_{i}}=0
$
and
$
h_{j}\left(\mathbf{x}^{*}\right)=0, j=1, \ldots, k .
$

## 2.9 Lemma 2.9

Let $ \mathbf{g} $ and $ \mathbf{h} $ be of class $ C^{(p)} $ on $ X_{0}, p \geq 1 $. Let $ \mathbf{x}^{*} $ be feasible, $ I=\left\{i: g_{i}\left(\mathbf{x}^{*}\right)<0\right\} $, $ E=\left\{i: g_{i}\left(\mathbf{x}^{*}\right)=0\right\} $, and let $ \mathbf{z} $ satisfy $ \nabla \mathbf{g}_{E}\left(\mathbf{x}^{*}\right) \mathbf{z} \leq \mathbf{0}, \nabla \mathbf{h}\left(\mathbf{x}^{*}\right) \mathbf{z}=\mathbf{0} $. Suppose that the vectors
$
\nabla g_{1}\left(\mathbf{x}^{*}\right), \ldots, \nabla g_{q}\left(\mathbf{x}^{*}\right), \nabla h_{1}\left(\mathbf{x}^{*}\right), \ldots, \nabla h_{k}\left(\mathbf{x}^{*}\right)
$
are linearly independent, where $ E_{1}=\{1,2, \ldots, q\}=\left\{i: i \in E,\left\langle\nabla g_{i}\left(\mathbf{x}^{*}\right), \mathbf{z}\right\rangle=0\right\} $. Then there exists a $ \tau>0 $ and a $ C^{(p)} $ mapping $ \xi(\cdot) $ from $ (-\tau, \tau) $ to $ \mathbb{R}^{n} $ such that
$
\begin{aligned}
\boldsymbol{\xi}(0)=\mathbf{x}^{*}, & \boldsymbol{\xi}^{\prime}(0)=\mathbf{z} \\
\mathbf{g}_{E_{1}}(\boldsymbol{\xi}(t))=\mathbf{0}, & \mathbf{h}(\boldsymbol{\xi}(t))=\mathbf{0}, \quad \mathbf{g}_{I}(\boldsymbol{\xi}(t))<\mathbf{0}, \\
\mathbf{g}_{E \backslash E_{1}}(\boldsymbol{\xi}(t))<\mathbf{0}, & \text { for } 0<|t|<\tau .
\end{aligned}
$

## 2.10 Fritz John Theorem

Let $ \mathrm{x}^{*} $ be a solution of the problem $ P $. Then there exists a real number $ \lambda_{0} \geq 0 $, a vector $ \boldsymbol{\lambda} \geq \mathbf{0} $ in $ \mathbb{R}^{m} $, and a vector $ \boldsymbol{\mu} $ in $ \mathbb{R}^{k} $ such that
(i) $ \left(\lambda_{0}, \boldsymbol{\lambda}, \boldsymbol{\mu}\right) \neq \mathbf{0} $,
(ii) $ \left\langle\boldsymbol{\lambda}, \mathbf{g}\left(\mathbf{x}^{*}\right)\right\rangle=0 $, and
(iii) $ \lambda_{0} \nabla f\left(\mathbf{x}^{*}\right)+\boldsymbol{\lambda}^{t} \nabla \mathbf{g}\left(\mathbf{x}^{*}\right)+\boldsymbol{\mu}^{t} \nabla \mathbf{h}\left(\mathbf{x}^{*}\right)=\mathbf{0} $.

## 2.11 Definition Critical Point

Critical Point: A (feasible) point $ \mathrm{x}^{*} $ at which the conclusion of Theorem 2.10 holds will be called a critical point for problem $ \mathbf{P} $.

## 2.13 Definition constrained qualification

The functions $ \mathbf{g} $ and $ \mathbf{h} $ satisfy the constraint qualification CQ at a feasible point $ \mathrm{x}_{0} $ if
(i) the vectors $ \nabla h_{1}\left(\mathbf{x}_{0}\right), \ldots, \nabla h_{k}\left(\mathbf{x}_{0}\right) $ are linearly independent and
(ii) the system
$
\nabla \mathbf{g}_{E}\left(\mathbf{x}_{0}\right) \mathbf{z}<\mathbf{0}, \quad \nabla \mathbf{h}\left(\mathbf{x}_{0}\right) \mathbf{z}=\mathbf{0},
$
has a solution $ \mathbf{z} $ in $ \mathbb{R}^{n} $. Here, $ E=\left\{i: g_{i}\left(\mathbf{x}_{0}\right)=0\right\} $.

## 2.14 Karush-Kuhn-Tucker Theorem

Let $ \mathbf{x}^{*} $ be a solution of problem $ \boldsymbol{P} $ and let $ C Q $ hold at $ \mathbf{x}^{*} $. Then $ \lambda_{0}>0 $ and there exists a vector $ \boldsymbol{\lambda} \geq \mathbf{0} $ in $ \mathbb{R}^{m} $ and a vector $ \boldsymbol{\mu} $ in $ \mathbb{R}^{k} $ such that
(i) $ \left\langle\boldsymbol{\lambda}, \mathbf{g}\left(\mathbf{x}^{*}\right)\right\rangle=0 $, and
(ii) $ \nabla f\left(\mathbf{x}^{*}\right)+\boldsymbol{\lambda}^{t} \nabla \mathbf{g}\left(\mathbf{x}^{*}\right)+\boldsymbol{\mu}^{t} \nabla \mathbf{h}\left(\mathbf{x}^{*}\right)=\mathbf{0} $.

## 2.15 Definition KKT Point, KKT pair 

KKT (stationary) Point: A point $ \mathrm{x}^{*} $ at which the conclusion of Theorem 2.14 holds will be called a KKT point for problem PI.
KKT Pair : A vector $ \left(\mathbf{x}^{*} ; \boldsymbol{\lambda} ; \boldsymbol{\mu}\right) $ at which the conclusion of Theorem 2.14 holds will be called a KKT pair for problem $ \mathbf{P} $.

## 2.16 Corollary LICQ

Let $ \mathbf{x}^{*} $ be a solution of problem $ \boldsymbol{P} $ such that $ E=\left\{i: g_{i}\left(\mathbf{x}^{*}\right)=0\right\}=\{1, \ldots, r\} $ and such that the vectors
$
\nabla g_{1}\left(\mathbf{x}^{*}\right), \ldots, \nabla g_{r}\left(\mathbf{x}^{*}\right), \nabla h_{1}\left(\mathbf{x}^{*}\right), \ldots, \nabla h_{k}\left(\mathbf{x}^{*}\right)
$
are linearly independent. Then the conclusion of Theorem 2.14 holds.

## 2.17 Sufficient Condition

Let $ f $ and $ \mathbf{g} $ be as in the statement of problem $ \boldsymbol{P} $ and let $ X_{0}, f $, and $ \mathbf{g} $ be convex and $ \mathbf{h} $ be affine, i.e. $ \mathbf{h}=\mathbf{A} \mathbf{x}+\mathbf{b} $. Let $ \mathbf{x}^{*} \in X_{0} $ be such that
(i) $ \mathbf{g}\left(\mathbf{x}^{*}\right) \leq \mathbf{0}, \mathbf{h}\left(\mathbf{x}^{*}\right)=\mathbf{0} $
(ii) $ \boldsymbol{\lambda} \geq \mathbf{0} $,
(iii) $ \left\langle\boldsymbol{\lambda}, \mathbf{g}\left(\mathbf{x}^{*}\right)\right\rangle=0 $, and
(iv) $ \nabla f\left(\mathbf{x}^{*}\right)+\boldsymbol{\lambda}^{t} \nabla \mathbf{g}\left(\mathbf{x}^{*}\right)+\boldsymbol{\mu}^{t} \nabla \mathbf{h}\left(\mathbf{x}^{*}\right)=\mathbf{0} $.

Then $ \mathbf{x}^{*} $ is a solution of problem $ \boldsymbol{P} $.

# 3 Convex Programming

## 3.1 Lemma 3.1

Let $ X $ be a nonempty convex set in $ \mathbb{R}^{n} $. Let $ \alpha: \mathbb{R}^{n} \rightarrow \mathbb{R} $ and $ \mathbf{g}: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m} $ be convex and let $ \mathbf{h} $ be affine, i.e. $ \mathbf{h}(\mathbf{x})=\mathbf{A} \mathbf{x}-\mathbf{b} $. If System 1 below has no solution $ \mathbf{x} $, then System 2 has a solution $ \left(\lambda_{0}, \boldsymbol{\lambda}, \boldsymbol{\mu}\right) $. The converse holds if $ \lambda_{0}>0 $.

System $ 1 \alpha(\mathbf{x})<0, \quad \mathbf{g}(\mathbf{x}) \leq \mathbf{0}, \quad \mathbf{h}(\mathbf{x})=\mathbf{0} $ for some $ \mathbf{x} \in X $
System $ 2 \lambda_{0} \alpha(\mathbf{x})+\lambda^{t} \mathbf{g}(\mathbf{x})+\boldsymbol{\mu}^{t} \mathbf{h}(\mathbf{x}) \geq 0 $ for all $ \mathbf{x} \in X \left(\lambda_{0}, \boldsymbol{\lambda}\right) \geq \mathbf{0}, \quad\left(\lambda_{0}, \boldsymbol{\lambda}, \boldsymbol{\mu}\right) \neq \mathbf{0} $.

## 3.2 Definition Generalized Lagrangian

Generalized Lagrangian:
$
\wedge\left(\mathbf{x}, \lambda_{0}, \boldsymbol{\lambda}, \boldsymbol{\mu}\right)=\lambda_{0} f(\mathbf{x})+\langle\boldsymbol{\lambda}, g(\mathbf{x})\rangle+\langle\boldsymbol{\mu}, \mathbf{h}(\mathbf{x})\rangle .
$

## 3.3 Theorem 3.3

Let $ f $ and g be convex on $ \mathbb{R}^{n} $ and let h be affine. Let $ \mathrm{x}^{*} $ be a solution of the problem $ C P $. Then there exists a real number $ \lambda_{0}^{*} \geq 0 $, a vector $ \lambda^{*} \geq 0 $ in $ \mathbb{R}^{m} $, and a vector $ \mu^{*} $ in $ \mathbb{R}^{m} $ such that
(i) $ \left(\lambda_{0}^{*}, \boldsymbol{\lambda}^{*}, \boldsymbol{\mu}^{*}\right) \neq \mathbf{0} $,
(ii) $ \left\langle\lambda^{*}, \mathrm{~g}\left(\mathrm{x}^{*}\right)\right\rangle=0 $, and
(iii) $ \wedge\left(\mathbf{x}^{*}, \lambda_{0}^{*}, \boldsymbol{\lambda}^{*}, \boldsymbol{\mu}^{*}\right)=\lambda_{0}^{*} f\left(\mathbf{x}^{*}\right) $, and
(iv) $ \wedge\left(\mathbf{x}^{*}, \lambda_{0}^{*}, \boldsymbol{\lambda}, \boldsymbol{\mu}\right) \leq \wedge\left(\mathbf{x}^{*}, \lambda_{0}^{*}, \boldsymbol{\lambda}^{*}, \boldsymbol{\mu}^{*}\right) \leq \wedge\left(\mathbf{x}, \lambda_{0}^{*}, \boldsymbol{\lambda}^{*}, \boldsymbol{\mu}^{*}\right) $ for all $ \mathbf{x} $ in $ \mathbb{R}^{n}, \boldsymbol{\lambda} \geq \mathbf{0} $ in $ \mathbb{R}^{n} $ and $ \boldsymbol{\mu} $ in $ \mathbb{R}^{k} $.

## 3.4 Definition Strongly Consistent

Strongly Consistent: The problem CP is said to be strongly consistent if there exists an $ \mathbf{x}_{0} $ such that $ \mathbf{g}\left(\mathbf{x}_{0}\right)<\mathbf{0} $ and $ \mathbf{h}\left(\mathbf{x}_{0}\right)=\mathbf{0} $.

## 3.5 Theorem 3.5

Let $ X_{0}=\mathbb{R}^{n}, f $ and $ \mathbf{g} $ be convex on $ \mathbb{R}^{n} $ and $ \mathbf{h}=\mathbf{A x}-\mathbf{b} $. Let $ \mathbf{A} $ have full rank. Let $ \mathrm{x}^{*} $ be a solution of the problem CP and the problem be strongly consistent. Then there exists a vector $ \boldsymbol{\lambda}^{*} \geq \mathbf{0} $ in $ \mathbb{R}^{m} $, and a vector $ \boldsymbol{\mu}^{*} $ in $ \mathbb{R}^{k} $ such that
(i) $ \left\langle\boldsymbol{\lambda}^{*}, \mathrm{~g}\left(\mathrm{x}^{*}\right)\right\rangle=0 $, and
(ii) $ L\left(\mathbf{x}^{*}, \boldsymbol{\lambda}^{*}, \boldsymbol{\mu}^{*}\right)=f\left(\mathbf{x}^{*}\right) $, and
(iii) $ L\left(\mathbf{x}^{*}, \boldsymbol{\lambda}, \boldsymbol{\mu}\right) \leq L\left(\mathbf{x}^{*}, \boldsymbol{\lambda}^{*}, \boldsymbol{\mu}^{*}\right) \leq L\left(\mathbf{x}, \boldsymbol{\lambda}^{*}, \boldsymbol{\mu}^{*}\right) $ for all $ \mathbf{x} \in X_{0} $ and $ \boldsymbol{\lambda} \geq \mathbf{0} $ in $ \mathbb{R}^{n} $,
where $ L(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\mu})=\wedge(\mathbf{x}, 1, \boldsymbol{\lambda}, \boldsymbol{\mu})=f(\mathbf{x})+\langle\boldsymbol{\lambda}, \mathbf{g}(\mathbf{x})\rangle+\langle\boldsymbol{\mu}, \mathbf{h}(\mathbf{x})\rangle $.

## 3.6 Theorem 3.6

Let $ \boldsymbol{C P} $ be strongly consistent, let $ \mathrm{x}^{*} $ be a solution, let $ \nu $ denote the value of the minimum, and let $ \lambda^{*}, \boldsymbol{\mu}^{*} $ be the multipliers associated with $ \mathbf{x}^{*} $ as in Theorem 3.5. Then
$
\begin{aligned}
\nu=L\left(\mathbf{x}^{*}, \boldsymbol{\lambda}^{*}, \boldsymbol{\mu}^{*}\right) & =\min _{\mathbf{x}} L\left(\mathbf{x}, \boldsymbol{\lambda}^{*}, \boldsymbol{\mu}^{*}\right) \\
& =\sup _{(\boldsymbol{\lambda}, \boldsymbol{\mu})} \inf _{\mathbf{x}} L(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\mu})=\inf _{\mathbf{x}} \sup _{(\boldsymbol{\lambda}, \boldsymbol{\mu})} L(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\mu}),
\end{aligned}
$
where $ \boldsymbol{\lambda} \in \mathbb{R}^{m}, \boldsymbol{\lambda} \geq \mathbf{0}, \boldsymbol{\mu} \in \mathbb{R}^{k}, \boldsymbol{x} \in \mathbb{R}^{n} $.

## 3.7 Theorem 3.7

Let $ f $ and g be convex and differentiable on $ X_{0}=\mathbb{R}^{n} $ and let $ \mathbf{h}=\mathbf{A x}-\mathbf{b} $. Let $ \mathbf{A} $ have full rank and the problem be strongly consistent. A necessary and sufficient condition that a feasible $ \mathrm{x}^{*} $ be a solution of the problem CP is that there exists a vector $ \boldsymbol{\lambda} \geq \mathbf{0} $ in $ \mathbb{R}^{m} $ and a vector $ \mu $ in $ \mathbb{R}^{k} $ such that
(i) $ \left\langle\boldsymbol{\lambda}, \mathbf{g}\left(\mathbf{x}^{*}\right)\right\rangle=0 $, and
(ii) $ \nabla f\left(\mathbf{x}^{*}\right)+\boldsymbol{\lambda}^{t} \nabla \mathbf{g}\left(\mathbf{x}^{*}\right)+\boldsymbol{\mu}^{t} \nabla \mathbf{h}\left(\mathbf{x}^{*}\right)=\mathbf{0} $.

# 4 Lagrangian Duality

# 4.1 Lagrangian Duality Theorem

(i) If $ X \neq \phi $ and $ Y \neq \phi $, then for each $ \mathrm{x} \in X $ and $ \eta \in Y $
$
\theta(\boldsymbol{\eta}) \leq f(\mathbf{x})
$

Moreover, if $ \delta $ and $ \nu $ are defined as before, then both are finite and $ \delta \leq \nu $.
(ii) Let $ Y \neq \phi $. If $ \theta(\boldsymbol{\eta}) $ is unbounded above on $ Y $, then $ X=\phi $.
(iii) Let $ X \neq \phi $. If $ f(\boldsymbol{x}) $ is unbounded below on $ X $, then $ Y=\phi $.
(iv) If there exists an $ \mathbf{x}^{*} \in X $ and $ \boldsymbol{\eta}^{*} \in Y $ such that $ f\left(\mathbf{x}^{*}\right)=\theta\left(\boldsymbol{\eta}^{*}\right) $, then $ \delta=f\left(\mathbf{x}^{*}\right)=\theta\left(\boldsymbol{\eta}^{*}\right)=\nu $. Thus $ \mathbf{x}^{*} $ is a solution of $ \boldsymbol{C P} $ and $ \boldsymbol{\eta}^{*} $ is a solution of DCP.

## 4.2 Definition Duality GPA

Duality Gap: Problems CP and DCP are said to exhibit a duality gap if $ \delta<\nu $.

## 4.3 Theorem 4.3

Let $ X_{0}=\mathbb{R}^{n}, A $ have full rank, the primal problem CP be strongly consistent and have a solution $ \mathrm{x}^{*} $. Then:
(i) There is no duality gap.
(ii) If $ \boldsymbol{\eta}^{*} $ is a multiplier for $ \boldsymbol{C P} $, then $ \boldsymbol{\eta}^{*} $ is a solution of the dual problem.
(iii) If $ \boldsymbol{\eta}_{0}=\left(\boldsymbol{\lambda}_{0}, \boldsymbol{\mu}_{0}\right) $ is a solution of the dual problem, then $ \left(\mathbf{x}^{*}, \boldsymbol{\eta}_{0}\right) $ is a KKT pair for the primal problem.



