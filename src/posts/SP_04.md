# Markov Chain

## Definition 

1. $\{X_n\}$ finite

2. $ \begin{array}{l}P\left\{X_{n+1}=j \mid X_{n}=i, X_{n-1}=i_{n-1}, \ldots X_{0}=i_{0}\right\} \\ =P\left\{X_{n+1}=j \mid X_{n}=i\right\}=P_{i j},\end{array} $